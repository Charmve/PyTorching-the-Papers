# PyTorchingThePaper
Study state-of-the-art papers with code ðŸ’ª

<!--
## StegaStamp: Invisible Hyperlinks in Physical Photographs
<p align="center">
  <a href="https://www.youtube.com/watch?v=E8OqgNDBGO0" target="_blank">
    <img src="https://res.cloudinary.com/marcomontalbano/image/upload/v1601457995/video_to_markdown/images/youtube--E8OqgNDBGO0-c05b58ac6eb4c4700831b2b3070cd403.jpg" alt="StegaStamp: Invisible Hyperlinks in Physical Photographs" width="426" height="240" />
  </a>
</p>
-->

<table>
	<tr>
		<td><font size="4">2.</font></td>
		<td><center><a href="https://www.youtube.com/watch?v=E8OqgNDBGO0" target="_blank"><img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5ca3b3c3ca205d53d7e986a1_pipeline-01-p-2000.png" alt="StegaStamp: Invisible Hyperlinks in Physical Photographs" width="426" height="%100" /><img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5ca400f82e5a6c5707af7189_pipeline_train-01-p-2000.png" alt="StegaStamp: Invisible Hyperlinks in Physical Photographs" width="1022" height="%100" /></a></center></td>
		<td>
			<p align="center"><font size="5"><b>StegaStamp</b>: Invisible Hyperlinks in Physical Photographs</font>
			<br> 
			<b>Matthew Tancikâˆ—</b>, Ben Mildenhallâˆ—, Ren Ng</p>
			<p align="left"><font size =2>
        <b>Abstract</b>. Printed and digitally displayed photos have the ability to hide imperceptible digital data that can be accessed through
internet-connected imaging systems. Another way to think about this is physical photographs that have unique QR codes invisibly embedded within them. This paper presents
an architecture, algorithms, and a prototype implementation addressing this vision. Our key technical contribution is StegaStamp, a learned steganographic algorithm to enable robust encoding and decoding of arbitrary hyperlink bitstrings into photos in a manner that approaches perceptual invisibility. StegaStamp comprises a deep neural network that learns an encoding/decoding algorithm robust to image perturbations approximating the space of distortions resulting from real printing and photography. We demonstrates real-time decoding of hyperlinks in photos from in-the-wild videos that contain variation in lighting, shadows, perspective, occlusion and viewing distance. Our prototype system robustly retrieves 56 bit hyperlinks after error correction â€“ sufficient to embed a unique code within every photo on the internet.
        </font>
      </p>
			<p align="center"><img width="%100" height="30" src="https://eccv2020.eu/wp-content/uploads/2020/05/eccv-online-logo_A.png"> AIM (ECCV 2020)
			<br>
			[<b><a href="https://arxiv.org/pdf/1904.05343.pdf" target="_blank">PDF</a></b> | <a href="https://www.matthewtancik.com/stegastamp" target="_blank"><b>Project Page</b></a> |  <a href="https://www.youtube.com/watch?v=E8OqgNDBGO0" target="_blank"><b>Video</b></a>  |  <a href="https://github.com/tancik/StegaStamp" target="_blank"><b>Code</b></a>]
			</p>
		</td>
	</tr>
  <tr>
		<td><font size="4">1.</font></td>
		<td><center><a href="https://www.youtube.com/watch?v=3YjkkxgAIKw" target="_blank"><img src="https://robinkips.github.io/CA-GAN/images/full_face_shades.png" alt="CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup Transfer" width="1022" height="%100" /></a></center></td>
		<td>
			<p align="center"><font size="4"><b>CA-GAN</b>: Weakly Supervised Color Aware GAN for Controllable Makeup Transfer</font>
			<br>
			<b>Robin Kips</b>, Pietro Gori, Matthieu Perrot, and Isabelle Bloch</p>
			<p align="left">
        <font size =2>
        <b>Abstract</b>. While existing makeup style transfer models perform an image synthesis whose results cannot be explicitly controlled, the ability to modify makeup color continuously is a desirable property for virtual try-on applications. We propose a new formulation for the makeup style transfer task, with the objective to learn a color controllable makeup style synthesis. We introduce CA-GAN, a generative model that learns to modify the color of specific objects (e.g. lips or eyes) in the image to an arbitrary target color while preserving background. Since color labels are rare and costly to acquire, our method leverages weakly supervised learning for conditional GANs. This enables to learn a controllable synthesis of complex objects, and only requires a weak proxy of the image attribute that we desire to modify. Finally, we present for the first time a quantitative analysis of makeup style transfer and color control performance.
        <br><b>Keywords</b>: Image Synthesis, GANs, Weakly Supervised Learning, Makeup Style Transfer
        </font>
      </p>
			<p align="center"><img width="%100" height="30" src="https://cvpr2019.thecvf.com/images/sponsors/cvf_.jpg"> CVPR 2020
			<br>
			[<b><a href="https://arxiv.org/pdf/2008.10298.pdf" target="_blank">PDF</a></b> | <a href="https://robinkips.github.io/CA-GAN/" target="_blank"><b>Project Page</b></a> |  <a href="https://www.youtube.com/watch?v=3YjkkxgAIKw&feature=emb_logo" target="_blank"><b>Video</b></a>  |  <a href="https://github.com/marsyy/littl_tools/tree/master/bluetooth" target="_blank"><b>Code</b></a>]
			</p>
		</td>
	</tr>
</table>
<br>
